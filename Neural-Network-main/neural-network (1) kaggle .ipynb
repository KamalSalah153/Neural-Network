{"metadata":{"accelerator":"GPU","colab":{"provenance":[],"include_colab_link":true},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/ahmedmabrouk24/Nueral-Network/blob/main/Neural_Network_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"code","source":"pip install tflearn ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1IkGsLnUUofU","outputId":"ca5495e8-ecac-4abf-d683-e1d9001e960a","execution":{"iopub.status.busy":"2022-12-23T03:08:48.418884Z","iopub.execute_input":"2022-12-23T03:08:48.419875Z","iopub.status.idle":"2022-12-23T03:09:02.500556Z","shell.execute_reply.started":"2022-12-23T03:08:48.419769Z","shell.execute_reply":"2022-12-23T03:09:02.499385Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting tflearn\n  Downloading tflearn-0.5.0.tar.gz (107 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m747.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from tflearn) (1.21.6)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from tflearn) (1.15.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from tflearn) (9.1.1)\nBuilding wheels for collected packages: tflearn\n  Building wheel for tflearn (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127299 sha256=4606bcd606c5b6adbb873b6fb41d4604827a86b3eb568c093583645600f2d70a\n  Stored in directory: /root/.cache/pip/wheels/5f/14/2e/1d8e28cc47a5a931a2fb82438c9e37ef9246cc6a3774520271\nSuccessfully built tflearn\nInstalling collected packages: tflearn\nSuccessfully installed tflearn-0.5.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install imgaug","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QW3jiwQ0J814","outputId":"36f15a38-06ec-4ab6-d32e-ff15e0031faa","execution":{"iopub.status.busy":"2022-12-23T03:09:02.504182Z","iopub.execute_input":"2022-12-23T03:09:02.504502Z","iopub.status.idle":"2022-12-23T03:09:12.162058Z","shell.execute_reply.started":"2022-12-23T03:09:02.504469Z","shell.execute_reply":"2022-12-23T03:09:12.160739Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: imgaug in /opt/conda/lib/python3.7/site-packages (0.4.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from imgaug) (1.15.0)\nRequirement already satisfied: imageio in /opt/conda/lib/python3.7/site-packages (from imgaug) (2.19.3)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from imgaug) (1.7.3)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from imgaug) (4.5.4.60)\nRequirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.7/site-packages (from imgaug) (1.21.6)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from imgaug) (3.5.3)\nRequirement already satisfied: Shapely in /opt/conda/lib/python3.7/site-packages (from imgaug) (1.8.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from imgaug) (9.1.1)\nRequirement already satisfied: scikit-image>=0.14.2 in /opt/conda/lib/python3.7/site-packages (from imgaug) (0.19.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.14.2->imgaug) (21.3)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.14.2->imgaug) (1.3.0)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.14.2->imgaug) (2021.11.2)\nRequirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.14.2->imgaug) (2.5)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->imgaug) (0.11.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->imgaug) (2.8.2)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->imgaug) (4.33.3)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->imgaug) (3.0.9)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->imgaug) (1.4.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->imgaug) (4.1.1)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.2->scikit-image>=0.14.2->imgaug) (5.1.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pyyaml h5py  # Required to save models in HDF5 format","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kGOkfZ5pnjdt","outputId":"24b00ebc-effb-4345-f07d-bb53e2105077","execution":{"iopub.status.busy":"2022-12-23T03:09:12.164125Z","iopub.execute_input":"2022-12-23T03:09:12.164527Z","iopub.status.idle":"2022-12-23T03:09:21.424381Z","shell.execute_reply.started":"2022-12-23T03:09:12.164482Z","shell.execute_reply":"2022-12-23T03:09:21.423208Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (6.0)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (3.7.0)\nRequirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from h5py) (1.21.6)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from random import shuffle\nfrom tqdm import tqdm\nimport tensorflow as tf\nimport pandas as pd\nfrom tensorflow.keras import layers,models,Sequential\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.layers import Dense, Conv2D, Activation, Flatten, Dropout, BatchNormalization, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\nfrom keras.saving.save import load_model\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tflearn\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.estimator import regression\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.regularizers import l2\nimport tensorflow as tf\nimport cv2\nimport random\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport imageio\nimport imgaug as ia\nimport imgaug.augmenters as iaa\nfrom PIL import Image\nimport shutil\nimport json\nfrom keras.applications.vgg16 import VGG16","metadata":{"id":"UE7tXC6EUtT6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"242bd022-0477-425f-a1e8-e2d47a841651","execution":{"iopub.status.busy":"2022-12-23T03:09:21.427519Z","iopub.execute_input":"2022-12-23T03:09:21.428226Z","iopub.status.idle":"2022-12-23T03:09:28.971642Z","shell.execute_reply.started":"2022-12-23T03:09:21.428179Z","shell.execute_reply":"2022-12-23T03:09:28.970650Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\nTRAIN_DIR = '/kaggle/input/nn23-sports-image-classification/Train'\nTEST_DIR = '/kaggle/input/nn23-sports-image-classification/Test'\ntrain_images=[]\ntest_images=[]\nval_images=[]\nSPORTS_DIR = []\nSPORTS_DIR.append('/kaggle/working/football')\nSPORTS_DIR.append('/kaggle/working/swimming')\nSPORTS_DIR.append('/kaggle/working/rowing')\nSPORTS_DIR.append('/kaggle/working/yoga')\nSPORTS_DIR.append('/kaggle/working/basketball')\nSPORTS_DIR.append('/kaggle/working/tennis')\nIMG_SIZE = 224\nnum_classes = 6\nMODEL_NAME = 'sports_classification-cnn'","metadata":{"id":"PzQu-hQeU2V2","execution":{"iopub.status.busy":"2022-12-23T03:09:28.973134Z","iopub.execute_input":"2022-12-23T03:09:28.973982Z","iopub.status.idle":"2022-12-23T03:09:28.983798Z","shell.execute_reply.started":"2022-12-23T03:09:28.973944Z","shell.execute_reply":"2022-12-23T03:09:28.981444Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def create_classes_files():\n    if (os.path.exists('/kaggle/working/football') == False):os.mkdir('/kaggle/working/football')\n    if (os.path.exists('/kaggle/working/swimming') == False):os.mkdir('/kaggle/working/swimming')\n    if (os.path.exists('/kaggle/working/rowing') == False):os.mkdir('/kaggle/working/rowing')\n    if (os.path.exists('/kaggle/working/yoga') == False):os.mkdir('/kaggle/working/yoga')\n    if (os.path.exists('/kaggle/working/basketball') == False):os.mkdir('/kaggle/working/basketball')\n    if (os.path.exists('/kaggle/working/tennis') == False):os.mkdir('/kaggle/working/tennis')\n    for img in tqdm(os.listdir(TRAIN_DIR)):\n        g = img.split('_')\n        img_name = g[0]\n        path = os.path.join(TRAIN_DIR, img)\n        img_data = Image.open(path) \n        img_data = img_data.resize((IMG_SIZE, IMG_SIZE))\n        if (img_name == 'Basketball'):\n            img_data = img_data.save('/kaggle/working/basketball/' + img)\n        elif(img_name == 'Football'):\n            img_data = img_data.save('/kaggle/working/football/' + img)\n        elif(img_name == 'Rowing'):\n            img_data = img_data.save('/kaggle/working/rowing/' + img)\n        elif(img_name == 'Yoga'):\n            img_data = img_data.save('/kaggle/working/yoga/' + img)\n        elif(img_name == 'Swimming'):\n            img_data = img_data.save('/kaggle/working/swimming/' + img)\n        elif(img_name == 'Tennis'):\n            img_data = img_data.save('/kaggle/working/tennis/' + img)\ncreate_classes_files()","metadata":{"execution":{"iopub.status.busy":"2022-12-23T03:09:28.985319Z","iopub.execute_input":"2022-12-23T03:09:28.985955Z","iopub.status.idle":"2022-12-23T03:09:56.486058Z","shell.execute_reply.started":"2022-12-23T03:09:28.985909Z","shell.execute_reply":"2022-12-23T03:09:56.485051Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"100%|██████████| 1681/1681 [00:27<00:00, 61.35it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_validation_folder():\n    if (os.path.exists('/kaggle/working/validation_data') == False):os.mkdir('/kaggle/working/validation_data')\n    for f in SPORTS_DIR:\n        cnt = 0\n        for img in tqdm(os.listdir(f)):\n            cnt+=1\n            if (cnt == 31):break\n            path = os.path.join(f, img)\n            img_data = Image.open(path) \n            image = img.split('.')\n            img_data = img_data.resize((IMG_SIZE, IMG_SIZE))\n            img_data = img_data.save('/kaggle/working/validation_data/'+ image[0] + '.jpg')\n            os.remove(path)\ncreate_validation_folder()","metadata":{"execution":{"iopub.status.busy":"2022-12-23T03:09:56.487786Z","iopub.execute_input":"2022-12-23T03:09:56.488506Z","iopub.status.idle":"2022-12-23T03:09:57.020768Z","shell.execute_reply.started":"2022-12-23T03:09:56.488467Z","shell.execute_reply":"2022-12-23T03:09:57.019672Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"  8%|▊         | 30/400 [00:00<00:01, 366.19it/s]\n 12%|█▎        | 30/240 [00:00<00:00, 321.46it/s]\n 15%|█▍        | 30/202 [00:00<00:00, 346.15it/s]\n  7%|▋         | 30/458 [00:00<00:01, 395.28it/s]\n 15%|█▌        | 30/196 [00:00<00:00, 357.43it/s]\n 16%|█▌        | 30/185 [00:00<00:00, 369.11it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def convert_all_image_to_jpg(path_file):\n    for img in tqdm(os.listdir(path_file)):\n        x = img.split(\".\")\n        path = path_file + '/' + img\n        name = path_file + '/' + x[0]\n        im = Image.open(path)\n        im.convert('RGB').save(name + \".jpg\")\n        if (x[1] != 'jpg'):\n             os.remove(path) \n                \nfor f in SPORTS_DIR:\n    convert_all_image_to_jpg(f)\nconvert_all_image_to_jpg('/kaggle/working/validation_data')","metadata":{"execution":{"iopub.status.busy":"2022-12-23T03:09:57.022453Z","iopub.execute_input":"2022-12-23T03:09:57.022828Z","iopub.status.idle":"2022-12-23T03:10:01.758236Z","shell.execute_reply.started":"2022-12-23T03:09:57.022791Z","shell.execute_reply":"2022-12-23T03:10:01.757184Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"100%|██████████| 370/370 [00:00<00:00, 373.64it/s]\n100%|██████████| 210/210 [00:00<00:00, 310.42it/s]\n100%|██████████| 172/172 [00:00<00:00, 361.89it/s]\n100%|██████████| 428/428 [00:01<00:00, 425.43it/s]\n100%|██████████| 166/166 [00:00<00:00, 266.81it/s]\n100%|██████████| 155/155 [00:00<00:00, 331.81it/s]\n100%|██████████| 180/180 [00:00<00:00, 389.81it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def augmentation(input_img):\n        list_data=[]\n\n    #Crop\n        crop2 = iaa.Crop(percent=(0, 0.2)) \n        input_crop2 = crop2.augment_image(input_img)\n        list_data.append(input_crop2)\n    #rotation\n        rot3 = iaa.Affine(rotate=(-40,20))\n        input_rot3 = rot3.augment_image(input_img)\n        list_data.append(input_rot3)\n    #blur\n        blur=iaa.Sometimes(\n        0.5,\n        iaa.GaussianBlur(sigma=(0, 0.5)))\n        input_blur=blur.augment_image(input_img)\n        list_data.append(input_blur)\n\n    #noise\n        noise2=iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)\n        input_noise2=noise2.augment_image(input_img)\n        list_data.append(input_noise2)\n        aug=iaa.Affine(\n        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n        rotate=(-25, 25),\n        shear=(-8, 8)\n        )\n        input_aug=aug.augment_image(input_img)\n        list_data.append(input_aug)\n    \n        return list_data","metadata":{"execution":{"iopub.status.busy":"2022-12-23T03:10:01.759820Z","iopub.execute_input":"2022-12-23T03:10:01.760214Z","iopub.status.idle":"2022-12-23T03:10:01.768967Z","shell.execute_reply.started":"2022-12-23T03:10:01.760175Z","shell.execute_reply":"2022-12-23T03:10:01.767750Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def balance_data():\n    for f in SPORTS_DIR:\n        cnt = 0\n        dir_of_sport = []\n        for img in tqdm(os.listdir(f)):\n            path = os.path.join(f, img)\n            cnt+=1\n            dir_of_sport.append(path)\n        for img in dir_of_sport:\n            path = img\n            img_data = cv2.imread(path,1)\n            img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)\n            img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n            list_aug_data = augmentation(img_data)\n            for lst in list_aug_data:\n                cnt+=1\n                if (cnt > 500):break\n                aug_img = Image.fromarray(lst)\n                if (f == '/kaggle/working/football'):\n                    aug_img = aug_img.save('/kaggle/working/football/'+ 'Football' + str(cnt) + '.jpg')\n                    \n                elif(f == '/kaggle/working/swimming'):\n                    aug_img = aug_img.save('/kaggle/working/swimming/'+ 'Swimming' + str(cnt) + '.jpg')\n                    \n                elif(f == '/kaggle/working/rowing'):\n                    aug_img = aug_img.save('/kaggle/working/rowing/'+ 'Rowing' + str(cnt) + '.jpg')\n                    \n                elif(f == '/kaggle/working/yoga'):\n                    aug_img = aug_img.save('/kaggle/working/yoga/'+ 'Yoga' + str(cnt) + '.jpg')\n                    \n                elif(f == '/kaggle/working/basketball'):\n                    aug_img = aug_img.save('/kaggle/working/basketball/'+ 'Basketball' + str(cnt) + '.jpg')\n                    \n                elif(f == '/kaggle/working/tennis'):\n                    aug_img = aug_img.save('/kaggle/working/tennis/'+ 'Tennis' + str(cnt) + '.jpg')\n                    \n            if (cnt > 500):break\n            \nbalance_data()           ","metadata":{"execution":{"iopub.status.busy":"2022-12-23T03:10:01.773480Z","iopub.execute_input":"2022-12-23T03:10:01.774338Z","iopub.status.idle":"2022-12-23T03:10:07.060120Z","shell.execute_reply.started":"2022-12-23T03:10:01.774302Z","shell.execute_reply":"2022-12-23T03:10:07.058981Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"100%|██████████| 370/370 [00:00<00:00, 286856.28it/s]\n100%|██████████| 210/210 [00:00<00:00, 303307.11it/s]\n100%|██████████| 172/172 [00:00<00:00, 291365.22it/s]\n100%|██████████| 428/428 [00:00<00:00, 343571.70it/s]\n100%|██████████| 166/166 [00:00<00:00, 452995.75it/s]\n100%|██████████| 155/155 [00:00<00:00, 284515.15it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_label(image_name):\n    img = image_name[0:4]\n    if img == 'Bask':\n        return 0\n    elif img == 'Foot':\n        return 1\n    elif img == 'Rowi':\n        return 2\n    elif img == 'Swim':\n        return 3\n    elif img == 'Tenn':\n        return 4\n    elif img == 'Yoga':\n        return 5","metadata":{"id":"18RVUzReXcaC","execution":{"iopub.status.busy":"2022-12-23T03:10:07.061651Z","iopub.execute_input":"2022-12-23T03:10:07.062343Z","iopub.status.idle":"2022-12-23T03:10:07.076978Z","shell.execute_reply.started":"2022-12-23T03:10:07.062305Z","shell.execute_reply":"2022-12-23T03:10:07.071219Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\ndef create_train_folder():\n    if (os.path.exists('/kaggle/working/train_data') == False):os.mkdir('/kaggle/working/train_data')\n    for f in SPORTS_DIR:\n        for img in tqdm(os.listdir(f)):\n            path = os.path.join(f, img)\n            img_data = Image.open(path)\n            img_data = img_data.save('/kaggle/working/train_data/' + img)\ncreate_train_folder()","metadata":{"execution":{"iopub.status.busy":"2022-12-23T03:10:07.079077Z","iopub.execute_input":"2022-12-23T03:10:07.079980Z","iopub.status.idle":"2022-12-23T03:10:15.449977Z","shell.execute_reply.started":"2022-12-23T03:10:07.079925Z","shell.execute_reply":"2022-12-23T03:10:15.448971Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"100%|██████████| 500/500 [00:01<00:00, 374.49it/s]\n100%|██████████| 500/500 [00:01<00:00, 368.84it/s]\n100%|██████████| 500/500 [00:01<00:00, 380.81it/s]\n100%|██████████| 500/500 [00:01<00:00, 388.42it/s]\n100%|██████████| 500/500 [00:01<00:00, 294.34it/s]\n100%|██████████| 500/500 [00:01<00:00, 381.58it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"NEW_TRAIN_DIR = \"/kaggle/working/train_data\"\nNEW_VALIDATION_DIR = \"/kaggle/working/validation_data\"","metadata":{"execution":{"iopub.status.busy":"2022-12-23T03:10:15.451488Z","iopub.execute_input":"2022-12-23T03:10:15.452358Z","iopub.status.idle":"2022-12-23T03:10:15.457641Z","shell.execute_reply.started":"2022-12-23T03:10:15.452316Z","shell.execute_reply":"2022-12-23T03:10:15.456463Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def create_train_data():\n    training_data = []\n    t = 0\n    for img in tqdm(os.listdir(NEW_TRAIN_DIR)):\n        path = os.path.join(NEW_TRAIN_DIR, img)\n        img_data = cv2.imread(path,1)\n        img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)\n\n        label_list = create_label(img)\n        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n        training_data.append([np.array(img_data), label_list])\n\n        #append augmentation to train data\n#         aug_list = augmentation(img_data);\n#         for aug in aug_list:\n#             training_data.append([np.array(aug), label_list])\n\n    print(\"Train size = \" , len(training_data))\n    shuffle(training_data)\n    np.save('train_data.npy', training_data)\n    return training_data","metadata":{"id":"YJIXofUWVeGS","execution":{"iopub.status.busy":"2022-12-23T03:10:15.459342Z","iopub.execute_input":"2022-12-23T03:10:15.459784Z","iopub.status.idle":"2022-12-23T03:10:15.468394Z","shell.execute_reply.started":"2022-12-23T03:10:15.459747Z","shell.execute_reply":"2022-12-23T03:10:15.467230Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"column1=[]\ndef create_test_data():\n    test_data = []\n    for img in tqdm(os.listdir(TEST_DIR)):\n        path = os.path.join(TEST_DIR, img)\n        img_data = cv2.imread(path,1)\n        column1.append(img)\n        img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)\n\n        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n        test_data.append([np.array(img_data), 0])\n\n    np.save('test_data.npy', test_data)\n    return test_data","metadata":{"id":"I5i17MYbkUQL","execution":{"iopub.status.busy":"2022-12-23T03:10:15.470083Z","iopub.execute_input":"2022-12-23T03:10:15.470521Z","iopub.status.idle":"2022-12-23T03:10:15.478399Z","shell.execute_reply.started":"2022-12-23T03:10:15.470486Z","shell.execute_reply":"2022-12-23T03:10:15.477299Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def create_validation_data():\n    validation_data = []\n    for img in tqdm(os.listdir(NEW_VALIDATION_DIR)):\n        path = os.path.join(NEW_VALIDATION_DIR, img)\n        img_data = cv2.imread(path,1)\n        img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)\n\n        label_list = create_label(img)\n        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n        validation_data.append([np.array(img_data), label_list])\n\n    shuffle(validation_data)\n    np.save('validation_data.npy', validation_data)\n    return validation_data","metadata":{"id":"rfqFr7y4yab5","execution":{"iopub.status.busy":"2022-12-23T03:10:15.479727Z","iopub.execute_input":"2022-12-23T03:10:15.480348Z","iopub.status.idle":"2022-12-23T03:10:15.489286Z","shell.execute_reply.started":"2022-12-23T03:10:15.480312Z","shell.execute_reply":"2022-12-23T03:10:15.488505Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"if (os.path.exists('train_data.npy')):\n    all_images = np.load('train_data.npy',allow_pickle=True)\nelse: \n    all_images = create_train_data()\n    \ntrain_images.clear();\nprint(\"all images = \",len(all_images))\nfor i in range(0 , len(all_images)):\n    train_images.append(all_images[i]);\n\nX_train = np.array([i[0] for i in train_images]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\ny_train = np.array([i[1] for i in train_images]).reshape(-1,)\n\n#==============================================================================================\n\nif (os.path.exists('validation_data.npy')):\n    all_images_val = np.load('validation_data.npy',allow_pickle=True)\nelse: \n    all_images_val = create_validation_data()\nval_images.clear();\nprint(\"all images = \",len(all_images_val))\nfor i in range(0 , len(all_images_val)):\n    val_images.append(all_images_val[i]);\n\nX_val = np.array([i[0] for i in val_images]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\nY_val = np.array([i[1] for i in val_images]).reshape(-1,)\n\n\n#==============================================================================================\n\nif (os.path.exists('test_data.npy')):\n    all_images_test = np.load('test_data.npy',allow_pickle=True)\nelse: \n    all_images_test = create_test_data()\ntest_images.clear()\nprint(\"all images = \",len(all_images_test))\nfor i in range(0 , len(all_images_test)):\n    test_images.append(all_images_test[i]);\n\nX_test = np.array([i[0] for i in test_images]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\nY_test = np.array([i[1] for i in test_images]).reshape(-1,)\n","metadata":{"id":"HIqOLdKrhNBO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"60148d72-9eb8-4cca-f847-3be24a307301","execution":{"iopub.status.busy":"2022-12-23T03:10:15.490624Z","iopub.execute_input":"2022-12-23T03:10:15.491762Z","iopub.status.idle":"2022-12-23T03:10:28.268807Z","shell.execute_reply.started":"2022-12-23T03:10:15.491726Z","shell.execute_reply":"2022-12-23T03:10:28.267696Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"100%|██████████| 3000/3000 [00:02<00:00, 1295.50it/s]\n/opt/conda/lib/python3.7/site-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n  arr = np.asanyarray(arr)\n","output_type":"stream"},{"name":"stdout","text":"Train size =  3000\nall images =  3000\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 180/180 [00:00<00:00, 1246.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"all images =  180\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 688/688 [00:09<00:00, 75.11it/s] \n","output_type":"stream"},{"name":"stdout","text":"all images =  688\n","output_type":"stream"}]},{"cell_type":"code","source":"\nmodel1 = VGG16(weights=\"imagenet\", include_top=False)\nmodel1 = Sequential([\n        layers.Conv2D(input_shape=(IMG_SIZE,IMG_SIZE,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n        layers.Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n        layers.MaxPool2D(pool_size=(2,2)),\n    \n        layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n        layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n        layers.MaxPool2D(pool_size=(2,2)),\n    \n        layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n        layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n        layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n        layers.Dropout(0.3),\n        layers.MaxPool2D(pool_size=(2,2)),\n    \n        layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n        layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n        layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n        layers.Dropout(0.2),\n        layers.MaxPool2D(pool_size=(2,2)),\n    \n        layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n        layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n        layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n        layers.Dropout(0.1),\n        layers.MaxPool2D(pool_size=(2,2)),\n        layers.Flatten(),\n        layers.Dense(units=256,activation=\"relu\"),\n        layers.Dense(units=256,activation=\"relu\"),\n        layers.Dense(units=6, activation=\"softmax\")\n])\nmodel1.compile(\n    optimizer= tf.keras.optimizers.Adam(learning_rate = 0.00001),\n    loss=SparseCategoricalCrossentropy(),\n    metrics=['accuracy'])\n\nmodel1.fit(X_train, y_train, validation_data = (X_val, Y_val), epochs = 30)\n#model1.fit(X_train, y_train, epochs = 20)\n#model1.save('model.h5')\n    \n","metadata":{"id":"iqCyaHSH86qa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4c74a03f-0f4e-4234-eb25-51185f9f5a0f","execution":{"iopub.status.busy":"2022-12-23T03:22:57.742823Z","iopub.execute_input":"2022-12-23T03:22:57.743239Z","iopub.status.idle":"2022-12-23T03:29:25.049123Z","shell.execute_reply.started":"2022-12-23T03:22:57.743204Z","shell.execute_reply":"2022-12-23T03:29:25.048096Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Train on 3000 samples, validate on 180 samples\nEpoch 1/30\n3000/3000 [==============================] - 14s 5ms/sample - loss: 1.4974 - acc: 0.4070 - val_loss: 1.3371 - val_acc: 0.5556\nEpoch 2/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 1.1292 - acc: 0.5590 - val_loss: 1.1269 - val_acc: 0.6389\nEpoch 3/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.9636 - acc: 0.6423 - val_loss: 1.0437 - val_acc: 0.6722\nEpoch 4/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.8351 - acc: 0.6940 - val_loss: 0.9920 - val_acc: 0.6778\nEpoch 5/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.7296 - acc: 0.7350 - val_loss: 0.9743 - val_acc: 0.6556\nEpoch 6/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.6632 - acc: 0.7680 - val_loss: 0.9115 - val_acc: 0.6889\nEpoch 7/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.5940 - acc: 0.7933 - val_loss: 0.8612 - val_acc: 0.6889\nEpoch 8/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.5379 - acc: 0.8247 - val_loss: 0.8391 - val_acc: 0.7556\nEpoch 9/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.4985 - acc: 0.8313 - val_loss: 0.8521 - val_acc: 0.7278\nEpoch 10/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.4219 - acc: 0.8653 - val_loss: 0.7917 - val_acc: 0.7444\nEpoch 11/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.3798 - acc: 0.8747 - val_loss: 0.7239 - val_acc: 0.7556\nEpoch 12/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.3627 - acc: 0.8817 - val_loss: 0.7367 - val_acc: 0.8056\nEpoch 13/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.2817 - acc: 0.9093 - val_loss: 0.6544 - val_acc: 0.7889\nEpoch 14/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.2479 - acc: 0.9223 - val_loss: 0.6853 - val_acc: 0.7778\nEpoch 15/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.2305 - acc: 0.9263 - val_loss: 0.6893 - val_acc: 0.7833\nEpoch 16/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.2097 - acc: 0.9353 - val_loss: 0.6166 - val_acc: 0.7944\nEpoch 17/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.1822 - acc: 0.9417 - val_loss: 0.6454 - val_acc: 0.8000\nEpoch 18/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.1870 - acc: 0.9387 - val_loss: 0.6918 - val_acc: 0.7611\nEpoch 19/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.1537 - acc: 0.9530 - val_loss: 0.6161 - val_acc: 0.8056\nEpoch 20/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.1258 - acc: 0.9590 - val_loss: 0.6085 - val_acc: 0.7833\nEpoch 21/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.1002 - acc: 0.9707 - val_loss: 0.6191 - val_acc: 0.7833\nEpoch 22/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.1038 - acc: 0.9657 - val_loss: 0.5791 - val_acc: 0.8333\nEpoch 23/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.1513 - acc: 0.9460 - val_loss: 0.6231 - val_acc: 0.8111\nEpoch 24/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.0756 - acc: 0.9813 - val_loss: 0.5767 - val_acc: 0.8222\nEpoch 25/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.0782 - acc: 0.9760 - val_loss: 0.6216 - val_acc: 0.8056\nEpoch 26/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.0859 - acc: 0.9733 - val_loss: 0.6269 - val_acc: 0.8000\nEpoch 27/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.0754 - acc: 0.9770 - val_loss: 0.6264 - val_acc: 0.8000\nEpoch 28/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.0462 - acc: 0.9883 - val_loss: 0.5816 - val_acc: 0.8278\nEpoch 29/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.0697 - acc: 0.9763 - val_loss: 0.8504 - val_acc: 0.7222\nEpoch 30/30\n3000/3000 [==============================] - 13s 4ms/sample - loss: 0.0380 - acc: 0.9910 - val_loss: 0.6254 - val_acc: 0.8167\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f10486a3790>"},"metadata":{}}]},{"cell_type":"code","source":"# os.remove(\"/kaggle/working/output.csv\")\n# os.remove(\"/kaggle/working/model.h5\")\n# os.remove(\"/kaggle/working/validation_data.npy\")\n# os.remove(\"/kaggle/working/train_data.npy\")\n# os.remove(\"/kaggle/working/test_data.npy\")\n# os.remove(\"/kaggle/working/best.csv\")\n# os.remove(\"/kaggle/working/vgg.csv\")\n# shutil.rmtree('/kaggle/working/train')\n# shutil.rmtree('/kaggle/working/validation_data')\nshutil.rmtree('/kaggle/working')","metadata":{"execution":{"iopub.status.busy":"2022-12-23T03:19:18.882839Z","iopub.status.idle":"2022-12-23T03:19:18.883673Z","shell.execute_reply.started":"2022-12-23T03:19:18.883417Z","shell.execute_reply":"2022-12-23T03:19:18.883444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(): \n  Y_test=model1.predict(X_test)\n  print(len(X_test))\n  prediction=[]\n  for i in Y_test:\n    prediction.append(np.argmax(i))\n  data={'image_name':column1,'label':prediction}\n  print(len(column1),len(prediction))\n  df=pd.DataFrame(data)\n  df.to_csv('best.csv',index=False)\n  print(df)\n\ntest()","metadata":{"execution":{"iopub.status.busy":"2022-12-23T03:29:34.813124Z","iopub.execute_input":"2022-12-23T03:29:34.813585Z","iopub.status.idle":"2022-12-23T03:29:36.795768Z","shell.execute_reply.started":"2022-12-23T03:29:34.813547Z","shell.execute_reply":"2022-12-23T03:29:36.794867Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"688\n688 688\n    image_name  label\n0      623.jpg      0\n1      208.jpg      5\n2      473.jpg      0\n3      333.jpg      1\n4      537.jpg      1\n..         ...    ...\n683    364.jpg      3\n684     90.jpg      3\n685    599.jpg      4\n686     25.jpg      1\n687    147.jpg      3\n\n[688 rows x 2 columns]\n","output_type":"stream"}]}]}