{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedmabrouk24/Nueral-Network/blob/main/Neural_Network_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N8Qx1CQeL-Kg"
      },
      "outputs": [],
      "source": [
        "def import_data():\n",
        "    from zipfile import ZipFile\n",
        "\n",
        "    with ZipFile('gdrive/MyDrive/NN Dataset.zip') as zipObj:\n",
        "\n",
        "      zipObj.extractall('gdrive/MyDrive/data')\n",
        "#import_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IkGsLnUUofU",
        "outputId": "ca5495e8-ecac-4abf-d683-e1d9001e960a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tflearn in /usr/local/lib/python3.8/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.21.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from tflearn) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "pip install tflearn "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW3jiwQ0J814",
        "outputId": "36f15a38-06ec-4ab6-d32e-ff15e0031faa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.8/dist-packages (0.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from imgaug) (1.15.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.8/dist-packages (from imgaug) (1.8.5.post1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from imgaug) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from imgaug) (3.2.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (from imgaug) (2.9.0)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.8/dist-packages (from imgaug) (0.18.3)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.8/dist-packages (from imgaug) (1.21.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from imgaug) (4.6.0.66)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from imgaug) (1.7.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->imgaug) (2022.10.10)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->imgaug) (2.8.8)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->imgaug) (1.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "pip install imgaug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnKIgh0rNN7p",
        "outputId": "4b1bd189-bbfe-45aa-d659-339d0c0a0ad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipyplot in /usr/local/lib/python3.8/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from ipyplot) (1.21.6)\n",
            "Requirement already satisfied: shortuuid in /usr/local/lib/python3.8/dist-packages (from ipyplot) (1.0.11)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.8/dist-packages (from ipyplot) (7.9.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from ipyplot) (7.1.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from IPython->ipyplot) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from IPython->ipyplot) (5.6.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from IPython->ipyplot) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from IPython->ipyplot) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from IPython->ipyplot) (4.8.0)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from IPython->ipyplot) (0.18.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from IPython->ipyplot) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from IPython->ipyplot) (57.4.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from IPython->ipyplot) (0.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->IPython->ipyplot) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->ipyplot) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->ipyplot) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->IPython->ipyplot) (0.7.0)\n"
          ]
        }
      ],
      "source": [
        "pip install ipyplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGOkfZ5pnjdt",
        "outputId": "24b00ebc-effb-4345-f07d-bb53e2105077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.8/dist-packages (from h5py) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyyaml h5py  # Required to save models in HDF5 format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UE7tXC6EUtT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "242bd022-0477-425f-a1e8-e2d47a841651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "        WARNING! Google Colab Environment detected!\n",
            "        You might encounter issues while running in Google Colab environment.\n",
            "        If images are not displaying properly please try setting `force_b64` param to `True`.\n",
            "        \n"
          ]
        }
      ],
      "source": [
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras import layers,models,Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Activation, Flatten, Dropout, BatchNormalization, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from keras.saving.save import load_model\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "import ipyplot\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PzQu-hQeU2V2"
      },
      "outputs": [],
      "source": [
        "\n",
        "TRAIN_DIR = 'drive/MyDrive/data/Train'\n",
        "TEST_DIR = 'drive/MyDrive/data/Test'\n",
        "train_images=[]\n",
        "test_images=[]\n",
        "val_images=[]\n",
        "IMG_SIZE = 50\n",
        "num_classes = 6\n",
        "MODEL_NAME = 'sports_classification-cnn'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "u3CTENfwmkx-"
      },
      "outputs": [],
      "source": [
        "def convert_all_image_to_jpg():\n",
        "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
        "        x = img.split(\".\")\n",
        "        path = 'drive/MyDrive/data/Train/' + img\n",
        "        name = 'drive/MyDrive/data/Train/' + x[0]\n",
        "        im = Image.open(path)\n",
        "        im.convert('RGB').save(name + \".jpg\")\n",
        "        if (x[1] != 'jpg'):\n",
        "             os.remove(path) \n",
        "#convert_all_image_to_jpg()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wblLTQ0BNTdi"
      },
      "outputs": [],
      "source": [
        "def augmentation(input_img):\n",
        "    list_data=[]\n",
        "    list_data.append(input_img)\n",
        "\n",
        "\n",
        "    #Crop\n",
        "    for i in range(0 , len(list_data)):\n",
        "\n",
        "        crop2 = iaa.Crop(percent=(0, 0.2)) \n",
        "        input_crop2 = crop2.augment_image(list_data[i])\n",
        "        list_data.append(input_crop2)\n",
        "\n",
        "    #shearing (random rotate)\n",
        "    for i in range(0 , len(list_data)):\n",
        "        rot3 = iaa.Affine(rotate=(-40,20))\n",
        "        input_rot3 = rot3.augment_image(list_data[i])\n",
        "        list_data.append(input_rot3)\n",
        "\n",
        "        rot4 = iaa.Affine(rotate=(40,20))\n",
        "        input_rot4 = rot4.augment_image(list_data[i])\n",
        "        list_data.append(input_rot4)\n",
        "\n",
        "    #noise\n",
        "    for i in range(0 , len(list_data)):\n",
        "        noise1=iaa.AdditiveGaussianNoise(10,15)\n",
        "        input_noise1=noise1.augment_image(list_data[i])\n",
        "        list_data.append(input_noise1)\n",
        "\n",
        "        noise2=iaa.AdditiveGaussianNoise(10,8)\n",
        "        input_noise2=noise2.augment_image(list_data[i])\n",
        "        list_data.append(input_noise2)\n",
        "\n",
        "    return list_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "18RVUzReXcaC"
      },
      "outputs": [],
      "source": [
        "def create_label(image_name):\n",
        "    img = image_name[0:4]\n",
        "    if img == 'Bask':\n",
        "        return 0\n",
        "    elif img == 'Foot':\n",
        "        return 1\n",
        "    elif img == 'Rowi':\n",
        "        return 2\n",
        "    elif img == 'Swim':\n",
        "        return 3\n",
        "    elif img == 'Tenn':\n",
        "        return 4\n",
        "    elif img == 'Yoga':\n",
        "        return 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YJIXofUWVeGS"
      },
      "outputs": [],
      "source": [
        "def create_train_data():\n",
        "    training_data = []\n",
        "    t = 0\n",
        "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
        "        if (t < 200):\n",
        "          t+=1\n",
        "          continue\n",
        "        path = os.path.join(TRAIN_DIR, img)\n",
        "        img_data = cv2.imread(path,1)\n",
        "        img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        label_list = create_label(img)\n",
        "        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n",
        "        training_data.append([np.array(img_data), label_list])\n",
        "\n",
        "        #append augmentation to train data\n",
        "        aug_list = augmentation(img_data);\n",
        "        for aug in aug_list:\n",
        "            training_data.append([np.array(aug), label_list])\n",
        "\n",
        "    print(\"Train size = \" , len(training_data))\n",
        "    shuffle(training_data)\n",
        "    np.save('train_data.npy', training_data)\n",
        "    return training_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column1=[]\n",
        "def create_test_data():\n",
        "    test_data = []\n",
        "    for img in tqdm(os.listdir(TEST_DIR)):\n",
        "      \n",
        "        path = os.path.join(TEST_DIR, img)\n",
        "        img_data = cv2.imread(path,1)\n",
        "        column1.append(img)\n",
        "        img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n",
        "        test_data.append([np.array(img_data), 0])\n",
        "\n",
        "    np.save('test_data.npy', test_data)\n",
        "    return test_data\n"
      ],
      "metadata": {
        "id": "I5i17MYbkUQL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rfqFr7y4yab5"
      },
      "outputs": [],
      "source": [
        "def create_validation_data():\n",
        "    validation_data = []\n",
        "    t = 0\n",
        "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
        "        if (t > 200):\n",
        "          break\n",
        "        t+=1\n",
        "        path = os.path.join(TRAIN_DIR, img)\n",
        "        img_data = cv2.imread(path,1)\n",
        "        img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        label_list = create_label(img)\n",
        "        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n",
        "        validation_data.append([np.array(img_data), label_list])\n",
        "\n",
        "    shuffle(validation_data)\n",
        "    np.save('validation_data.npy', validation_data)\n",
        "    return validation_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HIqOLdKrhNBO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60148d72-9eb8-4cca-f847-3be24a307301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all images =  28139\n",
            "all images =  201\n",
            "all images =  688\n"
          ]
        }
      ],
      "source": [
        "if (os.path.exists('train_data.npy')):\n",
        "    all_images = np.load('train_data.npy',allow_pickle=True)\n",
        "else: \n",
        "    all_images = create_train_data()\n",
        "\n",
        "print(\"all images = \",len(all_images))\n",
        "for i in range(0 , len(all_images)):\n",
        "  train_images.append(all_images[i]);\n",
        "\n",
        "X_train = np.array([i[0] for i in train_images]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "y_train = np.array([i[1] for i in train_images]).reshape(-1,)\n",
        "\n",
        "#==============================================================================================\n",
        "\n",
        "if (os.path.exists('validation_data.npy')):\n",
        "    all_images_val = np.load('validation_data.npy',allow_pickle=True)\n",
        "else: \n",
        "    all_images_val = create_validation_data()\n",
        "print(\"all images = \",len(all_images_val))\n",
        "for i in range(0 , len(all_images_val)):\n",
        "  val_images.append(all_images_val[i]);\n",
        "\n",
        "X_val = np.array([i[0] for i in val_images]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "Y_val = np.array([i[1] for i in val_images]).reshape(-1,)\n",
        "\n",
        "\n",
        "#==============================================================================================\n",
        "\n",
        "if (os.path.exists('test_data.npy')):\n",
        "    all_images_test = np.load('test_data.npy',allow_pickle=True)\n",
        "else: \n",
        "    all_images_test = create_test_data()\n",
        "print(\"all images = \",len(all_images_test))\n",
        "for i in range(0 , len(all_images_test)):\n",
        "  test_images.append(all_images_test[i]);\n",
        "\n",
        "X_test = np.array([i[0] for i in test_images]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "Y_test = np.array([i[1] for i in test_images]).reshape(-1,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iqCyaHSH86qa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c74a03f-0f4e-4234-eb25-51185f9f5a0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/init_ops.py:93: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/init_ops.py:93: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def CNN():\n",
        "    model1 = Sequential([\n",
        "            layers.Conv2D(filters = 64 ,kernel_size = (3, 3), input_shape = (IMG_SIZE, IMG_SIZE, 3), padding='same', activation='relu'),\n",
        "            layers.Conv2D(filters = 64 ,kernel_size = (3, 3), padding='same', activation='relu'),\n",
        "            layers.MaxPooling2D(pool_size = (2,2)),\n",
        "\n",
        "            layers.Conv2D(filters = 128 ,kernel_size = (3, 3), padding='same', activation='relu'),\n",
        "            layers.Conv2D(filters = 128 ,kernel_size = (3, 3), padding='same', activation='relu'),\n",
        "            layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "            layers.Conv2D(filters = 256 ,kernel_size = (3, 3), padding='same', activation='relu'),\n",
        "            layers.Conv2D(filters = 256 ,kernel_size = (3, 3), padding='same', activation='relu'),\n",
        "            layers.Conv2D(filters = 256 ,kernel_size = (3, 3), padding='same', activation='relu'),\n",
        "            layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "            layers.Conv2D(filters = 256 ,kernel_size = (3, 3), padding='same', activation='relu'),\n",
        "            layers.Conv2D(filters = 256 ,kernel_size = (3, 3), padding='same', activation='relu'),\n",
        "            layers.Conv2D(filters = 256 ,kernel_size = (3, 3), padding='same', activation='relu'),\n",
        "            layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "            layers.Conv2D(filters = 512 ,kernel_size = (3, 3), padding='same', activation='relu'),\n",
        "            layers.Conv2D(filters = 512 ,kernel_size = (3, 3), padding='same', activation='relu'),\n",
        "            layers.Conv2D(filters = 512 ,kernel_size = (3, 3), padding='same', activation='relu'),\n",
        "            layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(4096, activation='relu'),\n",
        "            layers.Dense(4096, activation='relu'),\n",
        "            layers.Dense(1000, activation='relu'),\n",
        "            #Dropout(0.5),\n",
        "            layers.Dense(6, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    model1.compile(\n",
        "        optimizer= tf.keras.optimizers.Adam(learning_rate = 0.00001),\n",
        "        loss=SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy'])\n",
        "    \n",
        "    model1.fit(X_train, y_train, validation_data = (X_val, Y_val), epochs = 5)\n",
        "    model1.save('drive/MyDrive/model.h5')\n",
        "\n",
        "\n",
        "if (os.path.exists('drive/MyDrive/model.h5')):\n",
        "      model1 = load_model('drive/MyDrive/model.h5')\n",
        "else : CNN()\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  Y_test=model1.predict(X_test)\n",
        "  print(len(X_test))\n",
        "  prediction=[]\n",
        "  for i in Y_test:\n",
        "    prediction.append(np.argmax(i))\n",
        "  data={'image_name':column1,'label':prediction}\n",
        "  print(len(column1),len(prediction))\n",
        "  df=pd.DataFrame(data)\n",
        "  df.to_csv('drive/MyDrive/output.csv',index=False)\n",
        "  print(df)\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "id": "1mg6tuRokFed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3db2a85e-c494-40cc-9ae0-c014da4ad94f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 688/688 [00:07<00:00, 90.07it/s] \n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "688\n",
            "688 688\n",
            "    image_name  label\n",
            "0        0.jpg      4\n",
            "1        1.jpg      4\n",
            "2      102.jpg      1\n",
            "3      100.jpg      1\n",
            "4       10.jpg      5\n",
            "..         ...    ...\n",
            "683     94.jpg      1\n",
            "684     97.jpg      1\n",
            "685     96.jpg      4\n",
            "686     98.jpg      0\n",
            "687     99.jpg      0\n",
            "\n",
            "[688 rows x 2 columns]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}