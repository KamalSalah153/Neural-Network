{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1c_SkoK-idhH0O_tY610H6_M-KiUcgvSA",
      "authorship_tag": "ABX9TyP0gzIM6KwNgatQHK/eqLpr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedmabrouk24/Nueral-Network/blob/main/Neural_Network-VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def import_data():\n",
        "    from zipfile import ZipFile\n",
        "\n",
        "    with ZipFile('gdrive/MyDrive/DataSet_Neural_Network/NN Dataset.zip') as zipObj:\n",
        "\n",
        "      zipObj.extractall('gdrive/MyDrive/data')\n",
        "#import_data()"
      ],
      "metadata": {
        "id": "N8Qx1CQeL-Kg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tflearn "
      ],
      "metadata": {
        "id": "1IkGsLnUUofU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e6b0101-89cb-4ace-9b60-dd1e3b1cbb9e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tflearn in /usr/local/lib/python3.8/dist-packages (0.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from tflearn) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install imgaug"
      ],
      "metadata": {
        "id": "QW3jiwQ0J814",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06cfd7c2-b15e-484d-85ca-9a62ff06d88a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.8/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.8/dist-packages (from imgaug) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from imgaug) (1.7.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from imgaug) (1.15.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.8/dist-packages (from imgaug) (1.8.5.post1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from imgaug) (3.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from imgaug) (7.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from imgaug) (4.6.0.66)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.8/dist-packages (from imgaug) (0.18.3)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (from imgaug) (2.9.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->imgaug) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->imgaug) (2.8.8)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->imgaug) (2022.10.10)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug) (1.4.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ipyplot"
      ],
      "metadata": {
        "id": "XnKIgh0rNN7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00fca5cc-e7c1-4bcc-9098-8f259f64b4db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipyplot in /usr/local/lib/python3.8/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from ipyplot) (1.21.6)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.8/dist-packages (from ipyplot) (7.9.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from ipyplot) (7.1.2)\n",
            "Requirement already satisfied: shortuuid in /usr/local/lib/python3.8/dist-packages (from ipyplot) (1.0.11)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from IPython->ipyplot) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from IPython->ipyplot) (2.0.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from IPython->ipyplot) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from IPython->ipyplot) (5.6.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from IPython->ipyplot) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from IPython->ipyplot) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from IPython->ipyplot) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from IPython->ipyplot) (4.4.2)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from IPython->ipyplot) (0.18.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->IPython->ipyplot) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->ipyplot) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->ipyplot) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->IPython->ipyplot) (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "import ipyplot\n",
        "from PIL import Image\n",
        "     "
      ],
      "metadata": {
        "id": "UE7tXC6EUtT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0395c218-42a3-42cb-ce06-1a70b8473c5b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "        WARNING! Google Colab Environment detected!\n",
            "        You might encounter issues while running in Google Colab environment.\n",
            "        If images are not displaying properly please try setting `force_b64` param to `True`.\n",
            "        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DIR = 'drive/MyDrive/data/Train'\n",
        "TEST_DIR = 'drive/MyDrive/data/Test'\n",
        "train_images=[]\n",
        "test_images=[]\n",
        "IMG_SIZE = 50\n",
        "num_classes = 6\n",
        "MODEL_NAME = 'sports_classification-cnn'\n"
      ],
      "metadata": {
        "id": "PzQu-hQeU2V2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_all_image_to_jpg():\n",
        "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
        "        x = img.split(\".\")\n",
        "        path = 'drive/MyDrive/data/Train/' + img\n",
        "        name = 'drive/MyDrive/data/Train/' + x[0]\n",
        "        im = Image.open(path)\n",
        "        im.convert('RGB').save(name + \".jpg\")\n",
        "        if (x[1] != 'jpg'):\n",
        "             os.remove(path) \n",
        "#convert_all_image_to_jpg()"
      ],
      "metadata": {
        "id": "u3CTENfwmkx-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augmentation(input_img):\n",
        "    list_data = []\n",
        "\n",
        "    #Horizontal Flip\n",
        "    hflip= iaa.Fliplr(p=1.0)\n",
        "    input_hf= hflip.augment_image(input_img) \n",
        "    list_data.append(input_hf)\n",
        "\n",
        "    #Crop\n",
        "    crop1 = iaa.Crop(percent=(0, 0.38)) \n",
        "    input_crop1 = crop1.augment_image(input_img)\n",
        "    list_data.append(input_crop1)\n",
        "\n",
        "    #shearing (random rotate)\n",
        "    rot1 = iaa.Affine(rotate=(-70,20))\n",
        "    input_rot1 = rot1.augment_image(input_img)\n",
        "    list_data.append(input_rot1)\n",
        "\n",
        "    rot2 = iaa.Affine(rotate=(70,20))\n",
        "    input_rot2 = rot2.augment_image(input_img)\n",
        "    list_data.append(input_rot2)\n",
        "\n",
        "    #noise\n",
        "    noise=iaa.AdditiveGaussianNoise(10,40)\n",
        "    input_noise=noise.augment_image(input_img)\n",
        "    list_data.append(input_noise)\n",
        "\n",
        "    #elistic\n",
        "    elastic = iaa.ElasticTransformation(alpha=2.0, sigma=0.5)\n",
        "    input_elastic = elastic.augment_image(input_img)\n",
        "    list_data.append(input_elastic)\n",
        "\n",
        "    return list_data"
      ],
      "metadata": {
        "id": "wblLTQ0BNTdi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_label(image_name):\n",
        "    word_label = image_name[0:4]\n",
        "    if word_label == 'Bask':\n",
        "        return np.array([1,0,0,0,0,0])\n",
        "    elif word_label == 'Foot':\n",
        "        return np.array([0,1,0,0,0,0])\n",
        "    elif word_label == 'Rowi':\n",
        "        return np.array([0,0,1,0,0,0])\n",
        "    elif word_label == 'Swim':\n",
        "        return np.array([0,0,0,1,0,0])\n",
        "    elif word_label == 'Tenn':\n",
        "        return np.array([0,0,0,0,1,0])\n",
        "    elif word_label == 'Yoga':\n",
        "        return np.array([0,0,0,0,0,1])"
      ],
      "metadata": {
        "id": "18RVUzReXcaC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train_data():\n",
        "    training_data = []\n",
        "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
        "\n",
        "        path = os.path.join(TRAIN_DIR, img)\n",
        "        img_data = cv2.imread(path,0)\n",
        "\n",
        "        label_list = create_label(img)\n",
        "        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n",
        "        training_data.append([np.array(img_data), label_list])\n",
        "\n",
        "        #append augmentation to train data\n",
        "        aug_list = augmentation(img_data);\n",
        "        for aug in aug_list:\n",
        "            training_data.append([np.array(aug), label_list])\n",
        "\n",
        "    shuffle(training_data)\n",
        "    np.save('train_data.npy', training_data)\n",
        "    return training_data"
      ],
      "metadata": {
        "id": "YJIXofUWVeGS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (os.path.exists('train_data.npy')):\n",
        "    all_images = np.load('train_data.npy',allow_pickle=True)\n",
        "else: \n",
        "    all_images = create_train_data()\n",
        "\n",
        "for i in range(0 , 10000):\n",
        "  train_images.append(all_images[i]);\n",
        "\n",
        "for i in range(10000 , len(all_images)):\n",
        "  test_images.append(all_images[i]);\n",
        "\n",
        "X_train = np.array([i[0] for i in train_images]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "y_train = [i[1] for i in train_images]\n",
        "X_test = np.array([i[0] for i in test_images]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "y_test = [i[1] for i in test_images]"
      ],
      "metadata": {
        "id": "HIqOLdKrhNBO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CNN():\n",
        "    conv_input = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
        "\n",
        "    conv1 = conv_2d(conv_input, 64, 3, activation='relu')\n",
        "    conv2 = conv_2d(conv1, 64, 3, activation='relu')\n",
        "    pool1 = max_pool_2d(conv2, 5)\n",
        "\n",
        "    conv3 = conv_2d(pool1, 128, 3, activation='relu')\n",
        "    conv4 = conv_2d(conv3, 128, 3, activation='relu')\n",
        "    pool2 = max_pool_2d(conv4, 5)\n",
        "  \n",
        "    conv5 = conv_2d(pool2, 256, 3, activation='relu')\n",
        "    conv6 = conv_2d(conv5, 256, 3, activation='relu')\n",
        "    conv7 = conv_2d(conv6, 256, 3, activation='relu')\n",
        "    pool3 = max_pool_2d(conv7, 5)\n",
        "\n",
        "    conv8 = conv_2d(pool3, 512, 3, activation='relu')\n",
        "    conv9 = conv_2d(conv8, 512, 3, activation='relu')\n",
        "    conv10 = conv_2d(conv9, 512, 3, activation='relu')\n",
        "    pool4 = max_pool_2d(conv10, 5)\n",
        "\n",
        "    conv11 = conv_2d(pool4, 512, 3, activation='relu')\n",
        "    conv12 = conv_2d(conv11, 512, 3, activation='relu')\n",
        "    conv13 = conv_2d(conv12, 512, 3, activation='relu')\n",
        "    pool5 = max_pool_2d(conv13, 5)\n",
        "\n",
        "    fully_layer1 = fully_connected(pool5, 4096, activation='relu')\n",
        "    fully_layer2 = fully_connected(fully_layer1, 4096, activation='relu')\n",
        "    fully_layer3 = fully_connected(fully_layer2, 1000, activation='relu')\n",
        "\n",
        "    fully_layer4 = dropout(fully_layer3, 0.5)\n",
        "\n",
        "    cnn_layers = fully_connected(fully_layer4, 6, activation='softmax')\n",
        "\n",
        "    cnn_layers = regression(cnn_layers, optimizer='Adam', learning_rate=0.01, loss='categorical_crossentropy', name='targets')\n",
        "    model = tflearn.DNN(cnn_layers, tensorboard_dir='log', tensorboard_verbose=3)\n",
        "    print (X_train.shape)\n",
        "\n",
        "    if (os.path.exists('model.tfl.meta')):\n",
        "        model.load('./model.tfl')\n",
        "    else:\n",
        "        model.fit({'input': X_train}, {'targets': y_train}, n_epoch=20,\n",
        "              validation_set=({'input': X_test}, {'targets': y_test}),\n",
        "              snapshot_step=500, show_metric=True, run_id=MODEL_NAME)\n",
        "        model.save('model.tfl')\n",
        "\n",
        "CNN()"
      ],
      "metadata": {
        "id": "iqCyaHSH86qa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e880936-bb17-4c9d-bb9f-218eb948ae49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Step: 781  | total loss: \u001b[1m\u001b[32m16.43407\u001b[0m\u001b[0m | time: 514.927s\n",
            "\u001b[2K\r| Adam | epoch: 005 | loss: 16.43407 - acc: 0.2863 -- iter: 09792/10000\n"
          ]
        }
      ]
    }
  ]
}